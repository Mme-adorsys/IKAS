# Environment Configuration Example
# Copy this file to .env and fill in your actual values

NODE_ENV=development
PORT=8000

# LLM Provider Configuration
# Available providers: gemini, ollama, anthropic, openai
LLM_PROVIDER=anthropic
LLM_MODEL=llama3
LLM_TEMPERATURE=0.1
LLM_MAX_TOKENS=8192
LLM_TOP_P=0.95
LLM_TIMEOUT=30000

# Provider-specific API Keys (fill in only what you need)
GEMINI_API_KEY=your-google-gemini-api-key-here
ANTHROPIC_API_KEY=your-anthropic-api-key-here
OPENAI_API_KEY=your-openai-api-key-here

# Ollama Configuration (for local models)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_KEEP_ALIVE=5m
OLLAMA_NUM_PREDICT=8192
OLLAMA_STREAM=false

# MCP Service URLs
KEYCLOAK_MCP_URL=http://localhost:8001
NEO4J_MCP_URL=http://localhost:8002

# Redis Configuration
REDIS_URL=redis://localhost:6379

# Health Check Configuration
HEALTH_CHECK_TIMEOUT=5000
HEALTH_CHECK_INTERVAL=30000

# Circuit Breaker Configuration
CIRCUIT_BREAKER_FAILURE_THRESHOLD=5
CIRCUIT_BREAKER_RECOVERY_TIMEOUT=30000

# Cache TTL Configuration (in seconds)
CACHE_TTL_USER_DATA=300
CACHE_TTL_COMPLIANCE_RESULTS=1800
CACHE_TTL_GRAPH_ANALYSIS=3600
CACHE_TTL_SYSTEM_METRICS=60
